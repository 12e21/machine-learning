# 10.1 决定下一步做什么

- 在机器学习中，有很多因素会影响模型的性能，如特征选择、模型复杂度、正则化参数等。
- 如果模型的表现不理想，我们需要决定下一步应该做什么来改进模型。
- 有些常见的方法是：
  - 获取更多的训练数据
  - 减少特征的数量
  - 增加特征的数量或增加多项式特征
  - 增加或减少正则化参数
- 但是，并不是所有的方法都适用于所有的情况，有些方法可能会有效，有些方法可能会无效或者反而造成过拟合或欠拟合。
- 因此，我们需要有一些指导原则来帮助我们选择最合适的方法。
- 这些指导原则包括：
  - 评估假设：使用训练集、验证集和测试集来评估模型的误差，并比较不同的假设或模型。
  - 模型选择：使用交叉验证集来选择最优的模型或参数，避免在测试集上过度优化。
  - 诊断偏差与方差：根据训练误差和验证误差来判断模型是否存在高偏差或高方差，并采取相应的措施。
  - 学习曲线：绘制训练集大小与训练误差和验证误差之间的关系，分析是否有更多数据或更复杂模型的必要。


# 10.2 模型选择和训练、验证、测试集

- 在机器学习中，我们可能需要尝试不同的模型或参数，比如多项式的次数、正则化系数λ等，来找到最优的模型或参数。
- 为了选择最优的模型或参数，我们需要将数据集分为训练集、验证集和测试集，通常按照6:2:2的比例随机划分。
- 我们使用训练集来训练不同的模型或参数，得到相应的θ。
- 我们使用验证集来比较不同的模型或参数在未见过的数据上的误差，选择最小化验证误差J cv (θ)的模型或参数。
- 我们使用测试集来评估最终选择的模型或参数在未见过的数据上的泛化误差J test (θ)。
- 对于线性回归和逻辑回归，我们可以使用代价函数来计算训练误差、验证误差和测试误差。对于逻辑回归，我们还可以使用分类错误率来评估模型。


# 10.3 诊断偏差和方差

- 在机器学习中，我们需要诊断我们的模型是否有高偏差（欠拟合）或高方差（过拟合）的问题，以便选择合适的改进策略。
- 为了诊断偏差和方差，我们可以绘制训练误差和验证误差随着模型复杂度（如多项式次数）或训练集大小的变化曲线。
- 如果训练误差和验证误差都很高，且相近，说明模型有高偏差问题，也就是欠拟合。此时，我们可以尝试增加更多的特征，增加多项式特征，或者减小正则化系数λ。
- 如果训练误差很低，而验证误差很高，且相差很大，说明模型有高方差问题，也就是过拟合。此时，我们可以尝试增加更多的训练数据，减少特征数量，或者增大正则化系数λ。


# 10.4 正则化和偏差/方差

- 在机器学习中，我们可以使用正则化来减少过拟合的问题，也就是降低模型的方差。
- 正则化的方法是在代价函数中加入一个正则化项，对模型参数进行惩罚，使得模型更加简单。
- 正则化的参数λ可以控制正则化的程度，如果λ太大，会导致模型过于简单，出现欠拟合，也就是增加了偏差；如果λ太小，会导致模型过于复杂，出现过拟合，也就是增加了方差。
- 我们可以使用交叉验证集来选择合适的λ值，使得交叉验证误差最小。


# 10.5 学习曲线

- 学习曲线是一种用来判断机器学习算法是否有偏差或方差问题的工具，它可以绘制出训练误差和验证误差随着训练集大小的变化曲线。
- 学习曲线可以帮助我们判断是否需要增加更多的训练数据，或者是否需要尝试其他方法来改进算法的性能。
- 如果学习曲线呈现出高偏差的情况，即训练误差和验证误差都很高且趋于一致，那么增加更多的训练数据是没有用的，我们需要尝试增加更多的特征或减小正则化系数λ。
- 如果学习曲线呈现出高方差的情况，即训练误差很低而验证误差很高且相差很大，那么增加更多的训练数据是有用的，我们也可以尝试减少特征数量或增大正则化系数λ。


# 10.6 决定接下来做什么

- 在应用机器学习的过程中，我们需要根据不同的情况选择不同的方法来改进算法的性能。
- 我们可以使用一些诊断法来判断算法是否有偏差或方差问题，以及是否需要更多的数据或更多的特征。
- 我们也可以使用误差分析来检查算法在哪些样本上表现不好，从而找出改进的方向。
- 我们还可以使用交叉验证集和测试集来评估不同的模型和参数，从而选择最优的方案。
- 我们应该避免随意地尝试各种方法，而是有目的地进行分析和测试，从而提高效率和效果。
