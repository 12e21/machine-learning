# 4.1 多元

- 在之前的课程中，我们利用房屋的大小这一个特征来预测房屋的价格，但是当特征量变多之后，就得改变应付此类问题的策略了
- 一些常用的表达：
  - n：表示有n个特征值
  - x(i)：表示第i个训练样本的特征向量
  - x_j(i)：表示第i个训练样本的第j个特征值
  - m：表示训练样本的数量
- 多变量线性回归模型的假设函数为：
  - h_θ(x) = θ_0 + θ_1x_1 + θ_2x_2 + ... + θ_nx_n
  - 可以用矩阵乘法简化为：
  - h_θ(x) = x θ^T 

# 4.2 多元梯度下降法
- 多变量线性回归模型的代价函数为：
  - J(θ) = (1/2m) ∑_(i=1)^m (h_θ(x(i)) - y(i))^2
  - 和单变量线性回归模型的代价函数相同，只是h_θ(x)的形式不同
- 多变量线性回归模型的梯度下降算法为：
  - repeat until convergence {
    - θ_j := θ_j - α (1/m) ∑_(i=1)^m (h_θ(x(i)) - y(i)) x_j(i)
    - simultaneously update for j = 0, ..., n
  }
  - 和单变量线性回归模型的梯度下降算法相同，只是h_θ(x)和x_j(i)的形式不同

  # 4.3 特征缩放

- 特征缩放是一种预处理数据的方法，目的是让不同的特征具有相近的尺度或范围，从而加快梯度下降法的收敛速度
- 特征缩放的原理：
  - 如果不同的特征具有不同数量级的尺度或范围，例如一个特征的取值范围是0-1000，另一个特征的取值范围是0-1，那么成本函数J(θ)会呈现一个椭圆形的等高线，梯度下降法会沿着椭圆形的轨迹缓慢收敛
  - 如果对不同的特征进行缩放，使它们的取值范围都在-1到1之间，那么成本函数J(θ)会呈现一个近似圆形的等高线，梯度下降法会沿着更直接的轨迹快速收敛
- 特征缩放的方法：
  - 常用的特征缩放方法有两种：标准化和归一化
  - 标准化：将每个特征减去其均值，再除以其标准差
    - x_j := (x_j - μ_j) / s_j
    - 其中 μ_j 是第j个特征的均值，s_j 是第j个特征的标准差
  - 归一化：将每个特征减去其最小值，再除以其最大值与最小值的差
    - x_j := (x_j - min_j) / (max_j - min_j)
    - 其中 min_j 是第j个特征的最小值，max_j 是第j个特征的最大值

# 4.5 特征和多项式回归

### 特征映射

- 我们可以将一个一维的特征 $x$ 映射到更高维度的特征 $x^2$，$x^3$，$x^4$ 等等，这样我们就可以用一个更高维度的函数来拟合我们的数据。

- 例如，我们可以将一个一维的特征 $x$ 映射到二维的特征 $[x,x^2]$，这样我们就可以用一个二次函数来拟合我们的数据。

- 这个过程叫做特征映射（feature mapping）。

### 多项式回归

- 多项式回归是一种线性回归的扩展，它使用多项式函数来拟合数据。

- 例如，我们可以使用一个二次多项式来拟合数据：$h_{\theta}(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2^2$

- 我们也可以使用三次、四次或更高次的多项式函数来拟合数据。

- 多项式回归中的一个问题是选择多项式的阶数。如果阶数太低，则模型会欠拟合；如果阶数太高，则模型会过拟合。

- 通常情况下，我们使用交叉验证来选择多项式的阶数。

# 4.6 正规方程
## 正规方程
正规方程是一种通过求解矩阵方程来最小化代价函数的方法。我们可以通过求导数为0的代价函数来推导出正规方程。正规方程的解是：

θ = (X^T X)^(-1) X^T y

其中，θ是我们要求的参数向量，X是特征矩阵，y是标签向量。这个公式可以直接计算出最小化代价函数的θ值。

- 特征矩阵 x = { x_0 , x_1 , x_2 , x_3 }

- 标签向量 y = { y }

## 方法选择

- 梯度下降：特征数量大时速度会更快(大于一万)

- 正规方程: 求解直接

# 4.7 正规方程不可逆情况求解

## 导致不可逆原因

- 多余特征 ( 两种特征线性相关 )

- 特征数相较于样本数过多 

## 解决方法

- 删除多余特征

- 删除部分特征,或正则化
